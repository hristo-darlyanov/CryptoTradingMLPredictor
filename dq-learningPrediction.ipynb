{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from collections import deque\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "from tickerData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = getTickerData(ticker=\"btc-usd\", period=\"max\", interval=\"1d\")\n",
    "df.drop(columns={'Adj Close', 'Date', 'Open'}, inplace=True)\n",
    "df.rename(columns={'High':'high','Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results', 'trading_bot')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m_, s = divmod(t, 60)\n",
    "    h, m = divmod(m_, 60)\n",
    "    return '{:02.0f}:{:02.0f}:{:02.0f}'.format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days = 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id='trading-v0',\n",
    "    entry_point='trading_env:TradingEnvironment',\n",
    "    max_episode_steps=trading_days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trading costs: 0.10% | Time costs: 0.01%'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_cost_bps = 1e-3\n",
    "time_cost_bps = 1e-4\n",
    "\n",
    "f'Trading costs: {trading_cost_bps:.2%} | Time costs: {time_cost_bps:.2%}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trading_env:trading_env logger started.\n",
      "INFO:trading_env:loading data for AAPL...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trading_env:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3073 entries, 33 to 3105\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   returns  3073 non-null   float64\n",
      " 1   ret_2    3073 non-null   float64\n",
      " 2   ret_5    3073 non-null   float64\n",
      " 3   ret_10   3073 non-null   float64\n",
      " 4   ret_21   3073 non-null   float64\n",
      " 5   rsi      3073 non-null   float64\n",
      " 6   macd     3073 non-null   float64\n",
      " 7   atr      3073 non-null   float64\n",
      " 8   stoch    3073 non-null   float64\n",
      " 9   ultosc   3073 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 264.1 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\memed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[42]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_environment = gym.make('trading-v0', \n",
    "                               ticker='AAPL',\n",
    "                               trading_days=trading_days,\n",
    "                               trading_cost_bps=trading_cost_bps,\n",
    "                               time_cost_bps=time_cost_bps)\n",
    "trading_environment.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = trading_environment.observation_space.shape[0]\n",
    "num_actions = trading_environment.action_space.n\n",
    "max_episode_steps = trading_environment.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNAgent:\n",
    "    def __init__(self, state_dim,\n",
    "                 num_actions,\n",
    "                 learning_rate,\n",
    "                 gamma,\n",
    "                 epsilon_start,\n",
    "                 epsilon_end,\n",
    "                 epsilon_decay_steps,\n",
    "                 epsilon_exponential_decay,\n",
    "                 replay_capacity,\n",
    "                 architecture,\n",
    "                 l2_reg,\n",
    "                 tau,\n",
    "                 batch_size):\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.experience = deque([], maxlen=replay_capacity)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.architecture = architecture\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "        self.online_network = self.build_model()\n",
    "        self.target_network = self.build_model(trainable=False)\n",
    "        self.update_target()\n",
    "\n",
    "        self.epsilon = epsilon_start\n",
    "        self.epsilon_decay_steps = epsilon_decay_steps\n",
    "        self.epsilon_decay = (epsilon_start - epsilon_end) / epsilon_decay_steps\n",
    "        self.epsilon_exponential_decay = epsilon_exponential_decay\n",
    "        self.epsilon_history = []\n",
    "\n",
    "        self.total_steps = self.train_steps = 0\n",
    "        self.episodes = self.episode_length = self.train_episodes = 0\n",
    "        self.steps_per_episode = []\n",
    "        self.episode_reward = 0\n",
    "        self.rewards_history = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tau = tau\n",
    "        self.losses = []\n",
    "        self.idx = tf.range(batch_size)\n",
    "        self.train = True\n",
    "\n",
    "    def build_model(self, trainable=True):\n",
    "        layers = []\n",
    "        n = len(self.architecture)\n",
    "        for i, units in enumerate(self.architecture, 1):\n",
    "            layers.append(Dense(units=units,\n",
    "                                input_dim=self.state_dim if i == 1 else None,\n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=l2(self.l2_reg),\n",
    "                                name=f'Dense_{i}',\n",
    "                                trainable=trainable))\n",
    "        layers.append(Dropout(.1))\n",
    "        layers.append(Dense(units=self.num_actions,\n",
    "                            trainable=trainable,\n",
    "                            name='Output'))\n",
    "        model = Sequential(layers)\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target(self):\n",
    "        self.target_network.set_weights(self.online_network.get_weights())\n",
    "\n",
    "    def epsilon_greedy_policy(self, state):\n",
    "        self.total_steps += 1\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        q = self.online_network.predict(state)\n",
    "        return np.argmax(q, axis=1).squeeze()\n",
    "\n",
    "    def memorize_transition(self, s, a, r, s_prime, not_done):\n",
    "        if not_done:\n",
    "            self.episode_reward += r\n",
    "            self.episode_length += 1\n",
    "        else:\n",
    "            if self.train:\n",
    "                if self.episodes < self.epsilon_decay_steps:\n",
    "                    self.epsilon -= self.epsilon_decay\n",
    "                else:\n",
    "                    self.epsilon *= self.epsilon_exponential_decay\n",
    "\n",
    "            self.episodes += 1\n",
    "            self.rewards_history.append(self.episode_reward)\n",
    "            self.steps_per_episode.append(self.episode_length)\n",
    "            self.episode_reward, self.episode_length = 0, 0\n",
    "\n",
    "        self.experience.append((s, a, r, s_prime, not_done))\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if self.batch_size > len(self.experience):\n",
    "            return\n",
    "        minibatch = map(np.array, zip(*sample(self.experience, self.batch_size)))\n",
    "        states, actions, rewards, next_states, not_done = minibatch\n",
    "\n",
    "        next_q_values = self.online_network.predict_on_batch(next_states)\n",
    "        best_actions = tf.argmax(next_q_values, axis=1)\n",
    "\n",
    "        next_q_values_target = self.target_network.predict_on_batch(next_states)\n",
    "        target_q_values = tf.gather_nd(next_q_values_target,\n",
    "                                       tf.stack((self.idx, tf.cast(best_actions, tf.int32)), axis=1))\n",
    "\n",
    "        targets = rewards + not_done * self.gamma * target_q_values\n",
    "\n",
    "        q_values = self.online_network.predict_on_batch(states)\n",
    "        q_values[[self.idx, actions]] = targets\n",
    "\n",
    "        loss = self.online_network.train_on_batch(x=states, y=q_values)\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        if self.total_steps % self.tau == 0:\n",
    "            self.update_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = .99,  # discount factor\n",
    "tau = 100  # target network update frequency\n",
    "architecture = (256, 256)  # units per layer\n",
    "learning_rate = 0.0001  # learning rate\n",
    "l2_reg = 1e-6  # L2 regularization\n",
    "replay_capacity = int(1e6)\n",
    "batch_size = 4096\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = .01\n",
    "epsilon_decay_steps = 250\n",
    "epsilon_exponential_decay = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "ddqn = DDQNAgent(state_dim=state_dim,\n",
    "                 num_actions=num_actions,\n",
    "                 learning_rate=learning_rate,\n",
    "                 gamma=gamma,\n",
    "                 epsilon_start=epsilon_start,\n",
    "                 epsilon_end=epsilon_end,\n",
    "                 epsilon_decay_steps=epsilon_decay_steps,\n",
    "                 epsilon_exponential_decay=epsilon_exponential_decay,\n",
    "                 replay_capacity=replay_capacity,\n",
    "                 architecture=architecture,\n",
    "                 l2_reg=l2_reg,\n",
    "                 tau=tau,\n",
    "                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_1 (Dense)             (None, 256)               2816      \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,379\n",
      "Trainable params: 69,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ddqn.online_network.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
