{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tickerData import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>2023-03-11</td>\n",
       "      <td>20187.876953</td>\n",
       "      <td>20792.525391</td>\n",
       "      <td>20068.660156</td>\n",
       "      <td>20632.410156</td>\n",
       "      <td>30180288176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>20628.029297</td>\n",
       "      <td>22185.031250</td>\n",
       "      <td>20448.806641</td>\n",
       "      <td>22163.949219</td>\n",
       "      <td>29279035521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>22156.406250</td>\n",
       "      <td>24550.837891</td>\n",
       "      <td>21918.199219</td>\n",
       "      <td>24197.533203</td>\n",
       "      <td>49466362688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>24201.765625</td>\n",
       "      <td>26514.716797</td>\n",
       "      <td>24081.183594</td>\n",
       "      <td>24746.074219</td>\n",
       "      <td>54622230164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>24770.925781</td>\n",
       "      <td>25240.615234</td>\n",
       "      <td>23964.910156</td>\n",
       "      <td>24375.960938</td>\n",
       "      <td>43655701450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3102 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date          open          high           low         close  \\\n",
       "0    2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1    2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2    2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3    2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4    2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "3097 2023-03-11  20187.876953  20792.525391  20068.660156  20632.410156   \n",
       "3098 2023-03-12  20628.029297  22185.031250  20448.806641  22163.949219   \n",
       "3099 2023-03-13  22156.406250  24550.837891  21918.199219  24197.533203   \n",
       "3100 2023-03-14  24201.765625  26514.716797  24081.183594  24746.074219   \n",
       "3101 2023-03-15  24770.925781  25240.615234  23964.910156  24375.960938   \n",
       "\n",
       "           volume  pred  \n",
       "0        21056800   1.0  \n",
       "1        34483200   1.0  \n",
       "2        37919700   0.0  \n",
       "3        36863600   1.0  \n",
       "4        26580100   0.0  \n",
       "...           ...   ...  \n",
       "3097  30180288176   0.0  \n",
       "3098  29279035521   0.0  \n",
       "3099  49466362688   0.0  \n",
       "3100  54622230164   1.0  \n",
       "3101  43655701450   0.0  \n",
       "\n",
       "[3102 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = getTickerData(ticker=\"btc-usd\", period=\"max\", interval=\"1d\")\n",
    "df.drop(columns={'Adj Close'}, inplace=True)\n",
    "df.rename(columns={'Date':'date', 'Open':'open', 'High':'high','Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)\n",
    "df = produce_prediction(df, 1, dropna=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.78619022],\n",
       "        [-0.7852786 ],\n",
       "        [-0.78650826],\n",
       "        [-0.7850883 ],\n",
       "        [-0.83379794]],\n",
       "\n",
       "       [[-0.78823951],\n",
       "        [-0.78596577],\n",
       "        [-0.78903128],\n",
       "        [-0.78564912],\n",
       "        [-0.83312067]],\n",
       "\n",
       "       [[-0.79008632],\n",
       "        [-0.78772863],\n",
       "        [-0.79086474],\n",
       "        [-0.78768939],\n",
       "        [-0.83294732]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.36835236],\n",
       "        [ 1.37731605],\n",
       "        [ 1.37175864],\n",
       "        [ 1.42244882],\n",
       "        [ 0.88319199]],\n",
       "\n",
       "       [[ 1.27685159],\n",
       "        [ 1.31422531],\n",
       "        [ 1.29460283],\n",
       "        [ 1.36811125],\n",
       "        [ 1.07386389]],\n",
       "\n",
       "       [[ 1.29709461],\n",
       "        [ 1.2476349 ],\n",
       "        [ 1.28734513],\n",
       "        [ 1.27553192],\n",
       "        [ 1.11875938]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = StandardScaler().fit_transform(df[df.columns.difference(['pred', 'date'])])\n",
    "target = df['pred']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "x_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 5, 50)             10400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lst = keras.Sequential() # initializing model\n",
    "\n",
    "# input layer and LSTM layer with 50 neurons\n",
    "lst.add(layers.LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "# outpute layer with sigmoid activation\n",
    "lst.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# defining loss function, optimizer, metrics and then compiling model\n",
    "lst.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "lst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5463 - val_loss: 0.7076 - val_accuracy: 0.5139\n",
      "Epoch 2/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5464 - val_loss: 0.7103 - val_accuracy: 0.5054\n",
      "Epoch 3/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5450 - val_loss: 0.7130 - val_accuracy: 0.5050\n",
      "Epoch 4/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5464 - val_loss: 0.7137 - val_accuracy: 0.5014\n",
      "Epoch 5/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5455 - val_loss: 0.7158 - val_accuracy: 0.5030\n",
      "Epoch 6/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5455 - val_loss: 0.7171 - val_accuracy: 0.5014\n",
      "Epoch 7/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5461 - val_loss: 0.7194 - val_accuracy: 0.5006\n",
      "Epoch 8/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5453 - val_loss: 0.7221 - val_accuracy: 0.5014\n",
      "Epoch 9/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5454 - val_loss: 0.7253 - val_accuracy: 0.5006\n",
      "Epoch 10/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5466 - val_loss: 0.7274 - val_accuracy: 0.5010\n",
      "Epoch 11/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5471 - val_loss: 0.7385 - val_accuracy: 0.5030\n",
      "Epoch 12/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5448 - val_loss: 0.7380 - val_accuracy: 0.5006\n",
      "Epoch 13/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5452 - val_loss: 0.7403 - val_accuracy: 0.5006\n",
      "Epoch 14/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5466 - val_loss: 0.7544 - val_accuracy: 0.5002\n",
      "Epoch 15/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5456 - val_loss: 0.7550 - val_accuracy: 0.5010\n",
      "Epoch 16/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5454 - val_loss: 0.7547 - val_accuracy: 0.5014\n",
      "Epoch 17/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5460 - val_loss: 0.7735 - val_accuracy: 0.4994\n",
      "Epoch 18/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5450 - val_loss: 0.7882 - val_accuracy: 0.4998\n",
      "Epoch 19/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5445 - val_loss: 0.7855 - val_accuracy: 0.5002\n",
      "Epoch 20/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5451 - val_loss: 0.7909 - val_accuracy: 0.4998\n",
      "Epoch 21/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5468 - val_loss: 0.7953 - val_accuracy: 0.5002\n",
      "Epoch 22/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5444 - val_loss: 0.8125 - val_accuracy: 0.5002\n",
      "Epoch 23/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5466 - val_loss: 0.8203 - val_accuracy: 0.4994\n",
      "Epoch 24/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5449 - val_loss: 0.8176 - val_accuracy: 0.5002\n",
      "Epoch 25/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5459 - val_loss: 0.8138 - val_accuracy: 0.4966\n",
      "Epoch 26/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5458 - val_loss: 0.8329 - val_accuracy: 0.4958\n",
      "Epoch 27/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5453 - val_loss: 0.8400 - val_accuracy: 0.4978\n",
      "Epoch 28/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5452 - val_loss: 0.8596 - val_accuracy: 0.4962\n",
      "Epoch 29/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5450 - val_loss: 0.8541 - val_accuracy: 0.4938\n",
      "Epoch 30/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5444 - val_loss: 0.8493 - val_accuracy: 0.4986\n",
      "Epoch 31/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5450 - val_loss: 0.8620 - val_accuracy: 0.4982\n",
      "Epoch 32/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5443 - val_loss: 0.8530 - val_accuracy: 0.4978\n",
      "Epoch 33/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5460 - val_loss: 0.8760 - val_accuracy: 0.4881\n",
      "Epoch 34/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5455 - val_loss: 0.8673 - val_accuracy: 0.4938\n",
      "Epoch 35/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5472 - val_loss: 0.8982 - val_accuracy: 0.4986\n",
      "Epoch 36/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5454 - val_loss: 0.9116 - val_accuracy: 0.4982\n",
      "Epoch 37/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5447 - val_loss: 0.8743 - val_accuracy: 0.4978\n",
      "Epoch 38/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5465 - val_loss: 0.8846 - val_accuracy: 0.4986\n",
      "Epoch 39/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5441 - val_loss: 0.8976 - val_accuracy: 0.4978\n",
      "Epoch 40/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5456 - val_loss: 0.9177 - val_accuracy: 0.4974\n",
      "Epoch 41/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5448 - val_loss: 0.9087 - val_accuracy: 0.4986\n",
      "Epoch 42/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5456 - val_loss: 0.9161 - val_accuracy: 0.4974\n",
      "Epoch 43/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5458 - val_loss: 0.9569 - val_accuracy: 0.4986\n",
      "Epoch 44/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5446 - val_loss: 0.9184 - val_accuracy: 0.4978\n",
      "Epoch 45/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5451 - val_loss: 0.8976 - val_accuracy: 0.4962\n",
      "Epoch 46/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5453 - val_loss: 0.9066 - val_accuracy: 0.4978\n",
      "Epoch 47/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5451 - val_loss: 0.9460 - val_accuracy: 0.4994\n",
      "Epoch 48/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5452 - val_loss: 0.9313 - val_accuracy: 0.4922\n",
      "Epoch 49/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5457 - val_loss: 0.9587 - val_accuracy: 0.4950\n",
      "Epoch 50/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5455 - val_loss: 0.9533 - val_accuracy: 0.4962\n",
      "Epoch 51/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5450 - val_loss: 0.9556 - val_accuracy: 0.4970\n",
      "Epoch 52/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5455 - val_loss: 0.9783 - val_accuracy: 0.4950\n",
      "Epoch 53/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5450 - val_loss: 0.9549 - val_accuracy: 0.4942\n",
      "Epoch 54/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5447 - val_loss: 0.9599 - val_accuracy: 0.4958\n",
      "Epoch 55/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5466 - val_loss: 1.0070 - val_accuracy: 0.4950\n",
      "Epoch 56/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5456 - val_loss: 0.9988 - val_accuracy: 0.4974\n",
      "Epoch 57/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5457 - val_loss: 1.0083 - val_accuracy: 0.4958\n",
      "Epoch 58/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5451 - val_loss: 0.9682 - val_accuracy: 0.4982\n",
      "Epoch 59/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5453 - val_loss: 0.9991 - val_accuracy: 0.4966\n",
      "Epoch 60/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5454 - val_loss: 0.9949 - val_accuracy: 0.4954\n",
      "Epoch 61/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5459 - val_loss: 1.0231 - val_accuracy: 0.4962\n",
      "Epoch 62/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5451 - val_loss: 0.9919 - val_accuracy: 0.4950\n",
      "Epoch 63/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5461 - val_loss: 1.0013 - val_accuracy: 0.4970\n",
      "Epoch 64/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5451 - val_loss: 1.0244 - val_accuracy: 0.4962\n",
      "Epoch 65/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5453 - val_loss: 1.0386 - val_accuracy: 0.4970\n",
      "Epoch 66/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5458 - val_loss: 1.0469 - val_accuracy: 0.4954\n",
      "Epoch 67/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5461 - val_loss: 1.0068 - val_accuracy: 0.4962\n",
      "Epoch 68/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5464 - val_loss: 1.0208 - val_accuracy: 0.4970\n",
      "Epoch 69/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5457 - val_loss: 1.0342 - val_accuracy: 0.4970\n",
      "Epoch 70/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5453 - val_loss: 1.0219 - val_accuracy: 0.4986\n",
      "Epoch 71/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5454 - val_loss: 1.0248 - val_accuracy: 0.4970\n",
      "Epoch 72/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5455 - val_loss: 1.0519 - val_accuracy: 0.4978\n",
      "Epoch 73/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5454 - val_loss: 1.0745 - val_accuracy: 0.4978\n",
      "Epoch 74/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5456 - val_loss: 1.0336 - val_accuracy: 0.4970\n",
      "Epoch 75/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5458 - val_loss: 1.0591 - val_accuracy: 0.4970\n",
      "Epoch 76/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5455 - val_loss: 1.0833 - val_accuracy: 0.4974\n",
      "Epoch 77/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5452 - val_loss: 1.0792 - val_accuracy: 0.4970\n",
      "Epoch 78/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5457 - val_loss: 1.0766 - val_accuracy: 0.4974\n",
      "Epoch 79/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5459 - val_loss: 1.0753 - val_accuracy: 0.4986\n",
      "Epoch 80/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5459 - val_loss: 1.0476 - val_accuracy: 0.4990\n",
      "Epoch 81/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5455 - val_loss: 1.0572 - val_accuracy: 0.4978\n",
      "Epoch 82/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5469 - val_loss: 1.0926 - val_accuracy: 0.4970\n",
      "Epoch 83/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5464 - val_loss: 1.1105 - val_accuracy: 0.4990\n",
      "Epoch 84/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5461 - val_loss: 1.1106 - val_accuracy: 0.4982\n",
      "Epoch 85/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5460 - val_loss: 1.1248 - val_accuracy: 0.4986\n",
      "Epoch 86/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5462 - val_loss: 1.1255 - val_accuracy: 0.4978\n",
      "Epoch 87/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5445 - val_loss: 1.0808 - val_accuracy: 0.4966\n",
      "Epoch 88/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5458 - val_loss: 1.1563 - val_accuracy: 0.4970\n",
      "Epoch 89/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5449 - val_loss: 1.1067 - val_accuracy: 0.4970\n",
      "Epoch 90/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5453 - val_loss: 1.0930 - val_accuracy: 0.4978\n",
      "Epoch 91/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5460 - val_loss: 1.1255 - val_accuracy: 0.4974\n",
      "Epoch 92/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5455 - val_loss: 1.1426 - val_accuracy: 0.4982\n",
      "Epoch 93/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5460 - val_loss: 1.1760 - val_accuracy: 0.4978\n",
      "Epoch 94/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5459 - val_loss: 1.1738 - val_accuracy: 0.4970\n",
      "Epoch 95/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5463 - val_loss: 1.1557 - val_accuracy: 0.4994\n",
      "Epoch 96/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5459 - val_loss: 1.1648 - val_accuracy: 0.4986\n",
      "Epoch 97/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5460 - val_loss: 1.1831 - val_accuracy: 0.4974\n",
      "Epoch 98/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5458 - val_loss: 1.1803 - val_accuracy: 0.4994\n",
      "Epoch 99/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5457 - val_loss: 1.1927 - val_accuracy: 0.4990\n",
      "Epoch 100/100\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5452 - val_loss: 1.1986 - val_accuracy: 0.4974\n"
     ]
    }
   ],
   "source": [
    "history = lst.fit(x_train, Y_train, epochs=100, batch_size=16,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 1ms/step - loss: 1.4612 - accuracy: 0.5137\n",
      "Test results - Loss: 1.4612120389938354 - Accuracy: 51.36876106262207%\n"
     ]
    }
   ],
   "source": [
    "x_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "# predicting target attribute on testing dataset\n",
    "test_results = lst.evaluate(x_test, Y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
